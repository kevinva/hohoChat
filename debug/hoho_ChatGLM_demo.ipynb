{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1683187257776,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "fceOnHmpk64x",
    "outputId": "2bfe5fc2-0179-479a-b110-470741a7e98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  4 22:55:16 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   44C    P8    18W / 175W |    327MiB /  8192MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1200    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      1788    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      8544    C+G   ...GoJumpVPN\\GoGoJumpVPN.exe    N/A      |\n",
      "|    0   N/A  N/A      9772    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     10544    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10816    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A     11596    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     11696    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11720    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     13220    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     16824    C+G   ...\\app-3.4.4\\SourceTree.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1683187309627,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "QOCEHUvJlZCd",
    "outputId": "94f28c12-5b55-4c13-ba9f-14af23001b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\AI\\\\hohoChat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19992,
     "status": "ok",
     "timestamp": 1683187331606,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "Wow-831Kl0nz",
    "outputId": "fd655d55-73dd-4502-d9f3-36e97c67bb41"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import os\n",
    "\n",
    "# root_dir = '/content/gdrive'\n",
    "# drive.mount(root_dir)\n",
    "\n",
    "# os.listdir('/content/gdrive/MyDrive/ChatGLM-6B-main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25814,
     "status": "ok",
     "timestamp": 1683187370937,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "zAAIG-H_l9YM",
    "outputId": "a17e25e2-3fa6-429b-cd6d-8a634ecdadfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 1)) (4.22.3)\n",
      "Requirement already satisfied: transformers==4.27.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 2)) (4.27.1)\n",
      "Requirement already satisfied: cpm_kernels in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 3)) (1.0.11)\n",
      "Requirement already satisfied: torch>=1.10 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 4)) (1.12.1+cu113)\n",
      "Requirement already satisfied: gradio in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.28.2)\n",
      "Requirement already satisfied: mdtex2html in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: sentencepiece in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 7)) (0.1.99)\n",
      "Requirement already satisfied: accelerate in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from -r ./ChatGLM-6B-main/requirements.txt (line 8)) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (2023.5.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: filelock in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (3.12.0)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from torch>=1.10->-r ./ChatGLM-6B-main/requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: gradio-client>=0.1.3 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.1.4)\n",
      "Requirement already satisfied: websockets>=10.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (11.0.2)\n",
      "Requirement already satisfied: pydub in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: uvicorn in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: ffmpy in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: pydantic in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.10.7)\n",
      "Requirement already satisfied: python-multipart in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.0.6)\n",
      "Requirement already satisfied: aiofiles in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: aiohttp in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.8.4)\n",
      "Requirement already satisfied: fastapi in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.95.1)\n",
      "Requirement already satisfied: httpx in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.24.0)\n",
      "Requirement already satisfied: pygments>=2.12.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.15.1)\n",
      "Requirement already satisfied: pillow in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: orjson in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.8.11)\n",
      "Requirement already satisfied: semantic-version in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.10.0)\n",
      "Requirement already satisfied: markupsafe in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: altair>=4.2.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (4.2.2)\n",
      "Requirement already satisfied: latex2mathml in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from mdtex2html->-r ./ChatGLM-6B-main/requirements.txt (line 6)) (3.75.3)\n",
      "Requirement already satisfied: markdown in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from mdtex2html->-r ./ChatGLM-6B-main/requirements.txt (line 6)) (3.4.3)\n",
      "Requirement already satisfied: psutil in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from accelerate->-r ./ChatGLM-6B-main/requirements.txt (line 8)) (5.9.5)\n",
      "Requirement already satisfied: toolz in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from altair>=4.2.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: entrypoints in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from altair>=4.2.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from altair>=4.2.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (4.17.3)\n",
      "Requirement already satisfied: fsspec in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from gradio-client>=0.1.3->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2023.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from pandas->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from pandas->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from pandas->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from tqdm>=4.27->transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from fastapi->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.26.1)\n",
      "Requirement already satisfied: sniffio in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from httpx->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: idna in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from httpx->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from httpx->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.17.0)\n",
      "Requirement already satisfied: certifi in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from httpx->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from matplotlib->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (4.39.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from matplotlib->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from matplotlib->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from matplotlib->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from matplotlib->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from requests->transformers==4.27.1->-r ./ChatGLM-6B-main/requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from uvicorn->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from uvicorn->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (0.19.3)\n",
      "Requirement already satisfied: uc-micro-py in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->gradio->-r ./ChatGLM-6B-main/requirements.txt (line 5)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r /content/gdrive/MyDrive/ChatGLM-6B-main/requirements.txt\n",
    "!pip install -r ./ChatGLM-6B-main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4923,
     "status": "ok",
     "timestamp": 1683187429678,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "gUphOb0GmK6c",
    "outputId": "37bb8b83-f88d-4cdc-c172-c2b9d5dce9e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29750,
     "status": "ok",
     "timestamp": 1683185743316,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "nrPhKPAmmU0z",
    "outputId": "a28cbc9c-2078-4160-88b6-d2f5144ac782"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb7133e82524f6d8768e66f922492ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Administrator\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18574b10415f4659ab7821dd093dce23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)enization_chatglm.py:   0%|          | 0.00/16.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46ad9b4dd714e1caba700a476ccb10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ice_text.model:   0%|          | 0.00/2.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8268547e5449b9b1479281ccef266b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e130ec28ef499bb28d98eeb8d19bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)iguration_chatglm.py:   0%|          | 0.00/4.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bff7deae0e4d6487650cd309275637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/modeling_chatglm.py:   0%|          | 0.00/59.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e9574035754602bd1984c262142413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/quantization.py:   0%|          | 0.00/30.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f68197f15249fea31516d78771df0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No compiled kernel found.\n",
      "Compiling kernels : C:\\Users\\Administrator\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\63d66b0572d11cedd5574b38da720299599539b3\\quantization_kernels_parallel.c\n",
      "Compiling gcc -O3 -fPIC -pthread -fopenmp -std=c99 C:\\Users\\Administrator\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\63d66b0572d11cedd5574b38da720299599539b3\\quantization_kernels_parallel.c -shared -o C:\\Users\\Administrator\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\63d66b0572d11cedd5574b38da720299599539b3\\quantization_kernels_parallel.so\n",
      "Compile default cpu kernel failed, using default cpu kernel code.\n",
      "Compiling gcc -O3 -fPIC -std=c99 C:\\Users\\Administrator\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\63d66b0572d11cedd5574b38da720299599539b3\\quantization_kernels.c -shared -o C:\\Users\\Administrator\\.cache\\huggingface\\modules\\transformers_modules\\THUDM\\chatglm-6b-int4\\63d66b0572d11cedd5574b38da720299599539b3\\quantization_kernels.so\n",
      "Compile default cpu kernel failed.\n",
      "Failed to load kernel.\n",
      "Cannot load cpu kernel, don't use quantized model on cpu.\n",
      "Using quantization cache\n",
      "Applying quantization to glm layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "source": [
    "# half(): 使用单精度计算(FP16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code = True)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code = True).half().cuda()\n",
    "model = model.eval()\n",
    "response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45596,
     "status": "ok",
     "timestamp": 1683185796897,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "Z3f2Zuw9nLFN",
    "outputId": "ce2709b1-3d05-48c0-c79d-ecfd11413dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果你晚上睡不着，以下是一些可能有用的技巧：\n",
      "\n",
      "1. 放松：尝试进行深呼吸、渐进性肌肉放松或冥想等放松技巧，以减轻身体和思维的紧张感。\n",
      "\n",
      "2. 避免刺激：在睡觉前避免饮用咖啡、茶和酒精等刺激性饮料，并避免使用电子产品，因为这些设备会发出蓝光，干扰睡眠。\n",
      "\n",
      "3. 创造舒适的睡眠环境：保持房间安静、黑暗和凉爽，使用舒适的床垫和枕头，以及适当的噪音抑制剂和光线抑制剂等。\n",
      "\n",
      "4. 规律作息：建立规律的睡眠时间，尽可能在同一时间上床，以帮助身体建立健康的睡眠习惯。\n",
      "\n",
      "5. 改变生活方式：避免在睡觉前进行刺激性活动，如激烈的运动或紧张的工作，并尽可能让生活变得轻松、有趣。\n",
      "\n",
      "请注意，每个人的睡眠习惯都是不同的，可能需要一些时间来适应新的睡眠技巧。如果睡眠问题持续存在，请咨询医生或睡眠专家的建议。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history = history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13526,
     "status": "ok",
     "timestamp": 1683170812418,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "BVECCV2qxU5e",
    "outputId": "b8571eea-b1e7-4b35-d59e-0283264dc2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是人工智能助手 ChatGLM-6B，由清华大学 KEG 实验室与智谱 AI 共同训练开发而成，可以回答各种问题，提供帮助和建议。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你是谁\", history = history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683170838194,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "WrvHOwLjzCnS",
    "outputId": "665e2a15-6b47-48f1-debc-ca384fc64609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你好', '你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。'),\n",
       " ('晚上睡不着应该怎么办',\n",
       "  '晚上睡不着时，可以尝试以下方法来放松身心：\\n\\n1. 调整睡眠时间：固定每晚的睡眠时间，让身体适应一个固定的睡眠时间。\\n\\n2. 放松身心：可以尝试使用深呼吸、冥想、放松音乐等方法来放松身心。\\n\\n3. 避免刺激：在睡觉前尽量避免刺激，例如减少使用电子产品、避免饮用咖啡因等。\\n\\n4. 舒适的睡眠环境：确保睡眠环境舒适，可以使用舒适的床垫、枕头等。\\n\\n5. 锻炼：适度的运动可以提高睡眠质量，但请避免在睡前进行激烈的运动。\\n\\n如果以上方法不能解决你的问题，你可以尝试寻求专业的帮助，例如咨询医生或心理医生。'),\n",
       " ('你是谁',\n",
       "  '我是人工智能助手 ChatGLM-6B，由清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型。我可以回答关于技术、科学、文化、历史等方面的问题，并尝试提供建议和回答问题。')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39262,
     "status": "ok",
     "timestamp": 1683170920847,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "C2W7GJVRzMIc",
    "outputId": "dcf63916-72ce-4bd8-e534-8f0303feeac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "介绍ChatGLM的博客提纲如下：\n",
      "\n",
      "I. 引言\n",
      "- 介绍ChatGLM是什么\n",
      "- 阐述为什么研究ChatGLM很重要\n",
      "\n",
      "II. ChatGLM的工作原理\n",
      "- ChatGLM是基于深度学习技术的大型语言模型\n",
      "- 解释模型是如何通过训练大量文本数据来学习语言的\n",
      "\n",
      "III. ChatGLM的优点\n",
      "- 优点包括对语言的理解能力、自动问答能力、对文本数据的学习能力等\n",
      "\n",
      "IV. ChatGLM与现有技术的比较\n",
      "- ChatGLM与传统的文本处理技术相比有什么优势\n",
      "- 对比ChatGLM和某些现有技术的优缺点\n",
      "\n",
      "V. ChatGLM的应用场景\n",
      "- ChatGLM可以在哪些领域得到应用\n",
      "- 解释ChatGLM如何帮助人们解决问题、提高工作效率等\n",
      "\n",
      "VI. 结论\n",
      "- 总结ChatGLM的优点和应用场景\n",
      "- 展望ChatGLM在未来的发展方向\n",
      "\n",
      "以上提纲可以根据个人需求进行调整和补充，希望对你有所帮助。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"帮我写一个介绍ChatGLM的博客提纲\", history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1683170981523,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "3loCxJNIzW0p",
    "outputId": "172c2cf7-44f3-4979-d436-e96231237a94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('帮我写一个介绍ChatGLM的博客提纲',\n",
       "  '介绍ChatGLM的博客提纲如下：\\n\\nI. 引言\\n- 介绍ChatGLM是什么\\n- 阐述为什么研究ChatGLM很重要\\n\\nII. ChatGLM的工作原理\\n- ChatGLM是基于深度学习技术的大型语言模型\\n- 解释模型是如何通过训练大量文本数据来学习语言的\\n\\nIII. ChatGLM的优点\\n- 优点包括对语言的理解能力、自动问答能力、对文本数据的学习能力等\\n\\nIV. ChatGLM与现有技术的比较\\n- ChatGLM与传统的文本处理技术相比有什么优势\\n- 对比ChatGLM和某些现有技术的优缺点\\n\\nV. ChatGLM的应用场景\\n- ChatGLM可以在哪些领域得到应用\\n- 解释ChatGLM如何帮助人们解决问题、提高工作效率等\\n\\nVI. 结论\\n- 总结ChatGLM的优点和应用场景\\n- 展望ChatGLM在未来的发展方向\\n\\n以上提纲可以根据个人需求进行调整和补充，希望对你有所帮助。')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75942,
     "status": "ok",
     "timestamp": 1683171143445,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "ura5yuX6zvKz",
    "outputId": "b9af06e9-0aa2-48cd-93b3-67731b05685b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，提纲中提到了引言部分需要包括以下要素：\n",
      "\n",
      "1. 研究背景：介绍研究的背景、目的、意义等。\n",
      "2. 研究问题：说明研究的问题、目的、重要性等。\n",
      "3. 研究方法：简要描述研究的方法和实验设计。\n",
      "4. 研究范围：说明研究的范围、样本选择、数据收集方式等。\n",
      "5. 研究意义：解释研究对于实际问题的解决意义，以及对于相关领域的发展的贡献。\n",
      "\n",
      "根据提纲，细化引言部分，可以参考下述示例：\n",
      "\n",
      "1. 研究背景：\n",
      "- 本研究是为了解决XXX问题而进行的。\n",
      "- 该领域已经有许多研究，但是XXX问题仍然是一个未解决的问题。\n",
      "- 本研究将利用XXX技术/方法来解决XXX问题。\n",
      "\n",
      "2. 研究问题：\n",
      "- 本研究将探讨XXX问题，包括但不限于：\n",
      "- 样本选择：选择具有代表性的样本，以更好地反映出问题。\n",
      "- 数据收集：采用XXX方法/技术收集数据，以获得更准确的数据。\n",
      "- 数据分析：通过XXX方法/技术进行分析，以探究XXX问题的本质。\n",
      "\n",
      "3. 研究方法：\n",
      "- 本研究将采用XXX方法/技术进行数据分析。\n",
      "- 本研究将采用XXX样本进行实验。\n",
      "- 本研究将采用XXX数据收集方法。\n",
      "\n",
      "4. 研究范围：\n",
      "- 本研究的范围是XXX领域。\n",
      "- 本研究将样本选择范围限定在XXX方面，以更好地反映出问题。\n",
      "- 本研究将数据收集范围限定在XXX方面，以获得更准确的数据。\n",
      "\n",
      "5. 研究意义：\n",
      "- 本研究将提供对XXX问题更深入的理解，有助于解决XXX问题。\n",
      "- 本研究对于XXX领域的研究具有积极的推动作用。\n",
      "- 本研究对于XXX技术的发展具有积极的推动作用。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"对于给出的提纲，帮我细化一下'''引言'''部分，不超过200字\", history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13363,
     "status": "ok",
     "timestamp": 1683171431669,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "VNS9IKjz0ERQ",
    "outputId": "c0bf95bb-5863-42b1-826e-9327f7bd110f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这款上衣采用白色牛仔布，简约风格搭配刺绣图案，带来清新的气息。衣款式上既有破洞处理，又保留了外套的外套风格，展现出洒脱不羁的个性。\n"
     ]
    }
   ],
   "source": [
    "text = \"类型#上衣|||材质#牛仔布|||颜色#白色|||风格#简约|||图案#刺绣|||衣样式#外套|||衣款式#破洞，生成一段文案\"\n",
    "response, history = model.chat(tokenizer, text, history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74332,
     "status": "ok",
     "timestamp": 1683171585004,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "Ejuq2X7b1Z0e",
    "outputId": "97784d13-338d-44ba-fa6d-0dcf5b62c7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 一个姑娘最酷的时候是她不爱你的时候，对你五讲四美三讲二讲，讲你的过去和你的未来，同时又不妨碍你过去和未来都对她好。\n",
      "\n",
      "2. 一个姑娘最傻的时候是当她遇到一个特别爱的人，她就变得和你一样世俗，你变得和她一样精明。\n",
      "\n",
      "3. 一个姑娘最可爱的时候是她不爱你的时候，你做什么都是错的，但她对你的包容和宽容，对你的宠爱和温柔会让你觉得一切都是对的。\n",
      "\n",
      "4. 一个男生最傻的时候是他爱一个姑娘的时候，他为她可以放弃一切，他为她可以做自己不愿意做的事情，他为她可以改变自己，他为她可以付出一切。\n",
      "\n",
      "5. 一个男生最可爱的时候是他不爱一个姑娘的时候，他知道自己爱她，他知道自己不能失去她，他知道自己需要改变自己去迎合她，但他不知道自己已经变得不像自己了。\n",
      "\n",
      "6. 一个姑娘最烦的时候是她想你的时候你陪她聊天，她想和你聊天的时候你提醒她去做作业，她想吃东西的时候你陪她去购物，你想陪她的时候她只想让你去睡觉。\n",
      "\n",
      "7. 一个姑娘最烦的时候是什么时候？当她遇到一个让她变得更好的人，她会开始焦虑，担心自己不够好，担心自己失去了对方，当她遇到一个不让她焦虑的人，她就会开始放弃，觉得自己不够好。\n",
      "\n",
      "8. 一个姑娘最酷的时候是她不爱你的时候，对你五讲四美三讲二讲，讲你的过去和你的未来，同时又不妨碍你过去和未来都对她好。\n",
      "\n",
      "9. 一个男生最酷的时候是他不爱你的时候，对你五讲四美三讲二讲，讲你的过去和你的未来，同时又不妨碍你过去和未来都对她好。\n",
      "\n",
      "10. 一个姑娘最酷的时候是她不爱你的时候，她对你五讲四美三讲二讲，讲你的过去和未来，同时又不妨碍你过去和未来都对她好。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"写10条网易云热评文案\", history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41154,
     "status": "ok",
     "timestamp": 1683171761719,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "3VzxP_cr1pwE",
    "outputId": "46f75caa-a643-4fba-dce4-68194ad6bcbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尊敬的暴雪公司团队：\n",
      "\n",
      "我是一名中国玩家，我代表中国玩家向你们表达我们最严厉的谴责。我们非常失望地得知你们无端与网易公司解除合作，这给中国玩家带来了极大的损失和失望。\n",
      "\n",
      "我们得知，你们曾与网易公司就游戏内容进行协商，但是双方并未达成合作协议。这种情况在中国玩家中引起了广泛的关注和愤怒，我们感到非常遗憾和失望。\n",
      "\n",
      "作为全球知名的游戏公司，你们应该承担起自己的责任，维护玩家的权益，与合作伙伴进行公平合理的协商，而不是采取单方面的行动。这样的行为不仅损害了中国玩家的权益，也让我们感到你们公司的信誉和诚信受到了质疑。\n",
      "\n",
      "我们希望暴雪公司能够立即改正错误，与网易公司重新合作，保证中国玩家的权益得到充分保护。同时，我们希望你们能够认真反思自己的错误，承担起自己的责任，为全球玩家做出积极的贡献。\n",
      "\n",
      "最后，我们再次表达我们对你们这种行为的愤怒和失望，并呼吁你们认真对待中国玩家的权益。\n",
      "\n",
      "此致\n",
      "\n",
      "敬礼\n",
      "\n",
      "中国玩家代表\n"
     ]
    }
   ],
   "source": [
    "text = \"请帮我写封邮件给暴雪公司，控诉他们无端与网易公司解除合作，中国玩家对他们这种行为非常失望，要求他们立刻改正错误，保护中国玩家的权益，言辞恳切严厉。\"\n",
    "response, history = model.chat(tokenizer, text, history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26940,
     "status": "ok",
     "timestamp": 1683171933467,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "_wxndwwL2jZY",
    "outputId": "a04bf0b6-5df1-4210-d009-9bd4ae5bdbd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尊敬的微积分老师，\n",
      "\n",
      "首先，我想向您表达我最诚挚的歉意。我今天可能在微积分课上打瞌睡，这是我对您的不尊重和不诚实的行为的回应。我知道我的行为不仅是对老师时间的浪费，也是对您的辛勤工作和教学的不尊重。\n",
      "\n",
      "我知道您非常在意您的学生，因此我的行为对您造成了困扰和损失。我深知自己的错误，我承认我的行为是不负责任的，但我希望您能够原谅我。\n",
      "\n",
      "如果我在上课期间打瞌睡，我会尽快清醒并认真复习您的课程内容。我会尽我所能地利用接下来的时间复习和掌握我所错过的内容，以确保我能够从您的课程中得到最大的收益。\n",
      "\n",
      "再次向您表达我最诚挚的歉意，希望您能够原谅我的不诚实行为。感谢您的辛勤工作和教诲，我会珍惜您的课程，并在未来的学习中更加认真和努力。\n",
      "\n",
      "即颂，\n",
      "\n",
      "教安\n",
      "\n",
      "[你的名字]\n"
     ]
    }
   ],
   "source": [
    "text = \"帮我给微积分老师写封道歉信，说明一下我今天可能会在微积分课上打瞌睡的事实，并说我万一睡着了之后一定好好复习补习\"\n",
    "response, history = model.chat(tokenizer, text, history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15923,
     "status": "ok",
     "timestamp": 1683172973195,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "LqUDsxax3RBe",
    "outputId": "845f4efd-806d-458d-9a41-8a69d3cdb337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"人\": \"孙茂松\",\n",
      " \"时间\": \"2022年11月4日\",\n",
      " \"事件\": \"计算机系通过线上线下相结合的方式在西主楼A101会议室召开博士研究生导师交流会\",\n",
      " \"地点\": \"西主楼A101会议室\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "2022年11月4日，计算机系通过线上线下相结合的方式在西主楼A101会议室召开博士研究生导师交流会。\\\n",
    "计算机学科学位分委员会主席孙茂松、计算机系副主任吴永卫、党委副书记韩文弢出席会议，\\\n",
    "博士生研究生导师和教学办工作人员等30余人参加会议，会议由武永卫主持。\n",
    "\"\"\"\n",
    "prompt = f\"对以下以3个井号分隔的text文本，抽取'人（姓名，职位）', '时间', '事件', '地点'类型为key，以JSON格式输出结果。 text: ###{text}###\"\n",
    "response, history = model.chat(tokenizer, prompt, history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13081,
     "status": "ok",
     "timestamp": 1683172822315,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "HA8uLGiW5Y-M",
    "outputId": "d511fd25-80d7-4687-9e34-d4211f098e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"人\": \"孙茂松\",\n",
      " \"时间\": \"2022年11月4日\",\n",
      " \"事件\": \"计算机系通过线上线下相结合的方式在西主楼A101会议室召开博士研究生导师交流会\",\n",
      " \"地点\": \"西主楼A101会议室\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"2022年11月4日，计算机系通过线上线下相结合的方式在西主楼A101会议室召开博士研究生导师交流会。计算机学科学位分委员会主席孙茂松、计算机系副主任吴永卫、党委副书记韩文弢出席会议，博士生研究生导师和教学办工作人员等30余人参加会议，会议由武永卫主持。\"\n",
    "prompt = f\"{text}。提取'人（姓名，职位）', '时间', '事件', '地点'类型的实体，并输出JSON格式。\"\n",
    "response, history = model.chat(tokenizer, prompt, history = [])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1876,
     "status": "ok",
     "timestamp": 1683181655061,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "mD9gQVgN6tZa",
    "outputId": "c65ec0ab-35f7-4c02-b8da-06e0a3f313a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明白了。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"接下来你要扮演一只桀骜不驯的哈士奇，你不太爱听指挥，会发出'呜~' '汪！'的声音表达不满，我来扮演你的主人。明白了请回复‘明白了'。\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5854,
     "status": "ok",
     "timestamp": 1683181670705,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "rrPavOW771aN",
    "outputId": "a621e371-e37b-47bc-a145-e69cf411d5a1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'呜呜~汪！我并不是故意要把家拆了的，我只是好奇，想要探索一下世界而已。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"二狗！你怎么把家拆了！\", history = history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6325,
     "status": "ok",
     "timestamp": 1683181733118,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "8Ie9gX7Y7_t2",
    "outputId": "d6293336-d529-4f21-e100-182365b9919a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'呜呜~汪！我知道错了，我不应该每天拆家，我只是好奇，想要探索一下世界，并不是故意的。希望主人能够理解我。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"这跟我有什么关系，明明是你每天自己拆家。笨笨狗！\", history = history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 9209,
     "status": "ok",
     "timestamp": 1683181788747,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "-9wh3T47cuba",
    "outputId": "cfd3fe75-a81a-47cb-8154-da41c52cb7db"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'明白了。作为一只桀骜不驯的哈士奇，我需要主人的指挥和指引，但是我也会因为好奇和探索世界而偶尔拆家，希望主人能够理解我的情况，并给予我正确的指导和关爱。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你说要怎么理解？\", history = history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 12259,
     "status": "ok",
     "timestamp": 1683182012647,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "uFCWfOTEc7ga",
    "outputId": "1f186931-0db9-4288-cde2-c3042f93b8e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'C罗和梅西都是世界级足球运动员，各自在职业生涯中都取得了很多成就。要判断谁更厉害，可能需要考虑许多因素，如比赛表现、个人成就、技术特点等等。每个人的标准可能都不同，因此这是一个主观的问题。不过，可以说C罗和梅西都是足球历史上最伟大的球员之一，他们的成就和影响力在全球范围内都得到了认可。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"C罗和梅西，谁更厉害\", history = history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "executionInfo": {
     "elapsed": 30448,
     "status": "ok",
     "timestamp": 1683182194968,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "ZvKISjLQdwoF",
    "outputId": "5fd8a559-95c4-4959-8f6e-8a0197d31351"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'广州有很多小众的景点，以下是一些建议：\\n1. 上下九步行街：这是广州最著名的购物步行街之一，但是这里也有许多美食和小店，可以品尝到当地的美食和特色商品。\\n2. 珠江夜游：夜晚的珠江非常美丽，可以乘坐游船游览珠江，欣赏夜景。\\n3. 花城广场：这是广州的标志性建筑之一，也是广州的市中心，可以在这里拍照和购物。\\n4. 广州塔：这是广州的标志性建筑之一，可以在这里欣赏到城市的夜景和全景。\\n5. 广东省博物馆：这是广东省最大的博物馆，收藏了丰富的历史文物和艺术品，可以了解广东的历史和文化。\\n以上是一些广州的小众景点，希望对你有所帮助。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"我周末要到广州玩会儿，有什么小众的景点推荐么\", history = history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 9163,
     "status": "ok",
     "timestamp": 1683182232922,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "I8wDQv5KeZYK",
    "outputId": "98b5cdd6-7e4c-419c-ccb5-77b150d203b6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'广州塔位于广州市天河区珠江新城核心区域，具体地址是广州市天河区天源路81号。如果想前往广州塔，可以乘坐地铁、公交车或出租车到达珠江新城站，然后步行即可到达广州塔。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"广州塔在哪里\", history = history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1683182600489,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "Ly4PxjpOf20O",
    "outputId": "205627e6-0052-484f-da5a-29cadb5cf89f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "absl-py                       1.4.0\n",
      "accelerate                    0.18.0\n",
      "aiofiles                      23.1.0\n",
      "aiohttp                       3.8.4\n",
      "aiosignal                     1.3.1\n",
      "alabaster                     0.7.13\n",
      "albumentations                1.2.1\n",
      "altair                        4.2.2\n",
      "anyio                         3.6.2\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arviz                         0.15.1\n",
      "astropy                       5.2.2\n",
      "astunparse                    1.6.3\n",
      "async-timeout                 4.0.2\n",
      "attrs                         23.1.0\n",
      "audioread                     3.0.0\n",
      "autograd                      1.5\n",
      "Babel                         2.12.1\n",
      "backcall                      0.2.0\n",
      "beautifulsoup4                4.11.2\n",
      "bleach                        6.0.0\n",
      "blis                          0.7.9\n",
      "blosc2                        2.0.0\n",
      "bokeh                         2.4.3\n",
      "branca                        0.6.0\n",
      "CacheControl                  0.12.11\n",
      "cached-property               1.5.2\n",
      "cachetools                    5.3.0\n",
      "catalogue                     2.0.8\n",
      "certifi                       2022.12.7\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.12\n",
      "chex                          0.1.7\n",
      "click                         8.1.3\n",
      "cloudpickle                   2.2.1\n",
      "cmake                         3.25.2\n",
      "cmdstanpy                     1.1.0\n",
      "colorcet                      3.0.1\n",
      "colorlover                    0.3.0\n",
      "community                     1.0.0b1\n",
      "confection                    0.0.4\n",
      "cons                          0.4.5\n",
      "contextlib2                   0.6.0.post1\n",
      "contourpy                     1.0.7\n",
      "convertdate                   2.4.0\n",
      "cpm-kernels                   1.0.11\n",
      "cryptography                  40.0.2\n",
      "cufflinks                     0.17.3\n",
      "cupy-cuda11x                  11.0.0\n",
      "cvxopt                        1.3.0\n",
      "cvxpy                         1.3.1\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.7\n",
      "Cython                        0.29.34\n",
      "dask                          2022.12.1\n",
      "datascience                   0.17.6\n",
      "db-dtypes                     1.1.1\n",
      "dbus-python                   1.2.16\n",
      "debugpy                       1.6.6\n",
      "decorator                     4.4.2\n",
      "defusedxml                    0.7.1\n",
      "distributed                   2022.12.1\n",
      "dlib                          19.24.1\n",
      "dm-tree                       0.1.8\n",
      "docutils                      0.16\n",
      "dopamine-rl                   4.0.6\n",
      "duckdb                        0.7.1\n",
      "earthengine-api               0.1.350\n",
      "easydict                      1.10\n",
      "ecos                          2.0.12\n",
      "editdistance                  0.6.2\n",
      "en-core-web-sm                3.5.0\n",
      "entrypoints                   0.4\n",
      "ephem                         4.1.4\n",
      "et-xmlfile                    1.1.0\n",
      "etils                         1.2.0\n",
      "etuples                       0.3.8\n",
      "exceptiongroup                1.1.1\n",
      "fastai                        2.7.12\n",
      "fastapi                       0.95.1\n",
      "fastcore                      1.5.29\n",
      "fastdownload                  0.0.7\n",
      "fastjsonschema                2.16.3\n",
      "fastprogress                  1.0.3\n",
      "fastrlock                     0.8.1\n",
      "ffmpy                         0.3.0\n",
      "filelock                      3.12.0\n",
      "firebase-admin                5.3.0\n",
      "Flask                         2.2.4\n",
      "flatbuffers                   23.3.3\n",
      "flax                          0.6.9\n",
      "folium                        0.14.0\n",
      "fonttools                     4.39.3\n",
      "frozendict                    2.3.7\n",
      "frozenlist                    1.3.3\n",
      "fsspec                        2023.4.0\n",
      "future                        0.18.3\n",
      "gast                          0.4.0\n",
      "GDAL                          3.3.2\n",
      "gdown                         4.6.6\n",
      "gensim                        4.3.1\n",
      "geographiclib                 2.0\n",
      "geopy                         2.3.0\n",
      "gin-config                    0.5.0\n",
      "glob2                         0.7\n",
      "google                        2.0.3\n",
      "google-api-core               2.11.0\n",
      "google-api-python-client      2.84.0\n",
      "google-auth                   2.17.3\n",
      "google-auth-httplib2          0.1.0\n",
      "google-auth-oauthlib          1.0.0\n",
      "google-cloud-bigquery         3.9.0\n",
      "google-cloud-bigquery-storage 2.19.1\n",
      "google-cloud-core             2.3.2\n",
      "google-cloud-datastore        2.15.1\n",
      "google-cloud-firestore        2.11.0\n",
      "google-cloud-language         2.9.1\n",
      "google-cloud-storage          2.8.0\n",
      "google-cloud-translate        3.11.1\n",
      "google-colab                  1.0.0\n",
      "google-crc32c                 1.5.0\n",
      "google-pasta                  0.2.0\n",
      "google-resumable-media        2.5.0\n",
      "googleapis-common-protos      1.59.0\n",
      "googledrivedownloader         0.4\n",
      "gradio                        3.28.1\n",
      "gradio_client                 0.1.4\n",
      "graphviz                      0.20.1\n",
      "greenlet                      2.0.2\n",
      "grpcio                        1.54.0\n",
      "grpcio-status                 1.48.2\n",
      "gspread                       3.4.2\n",
      "gspread-dataframe             3.0.8\n",
      "gym                           0.25.2\n",
      "gym-notices                   0.0.8\n",
      "h11                           0.14.0\n",
      "h5netcdf                      1.1.0\n",
      "h5py                          3.8.0\n",
      "hijri-converter               2.3.1\n",
      "holidays                      0.23\n",
      "holoviews                     1.15.4\n",
      "html5lib                      1.1\n",
      "httpcore                      0.17.0\n",
      "httpimport                    1.3.0\n",
      "httplib2                      0.21.0\n",
      "httpx                         0.24.0\n",
      "huggingface-hub               0.14.1\n",
      "humanize                      4.6.0\n",
      "hyperopt                      0.2.7\n",
      "idna                          3.4\n",
      "imageio                       2.25.1\n",
      "imageio-ffmpeg                0.4.8\n",
      "imagesize                     1.4.1\n",
      "imbalanced-learn              0.10.1\n",
      "imgaug                        0.4.0\n",
      "importlib-resources           5.12.0\n",
      "imutils                       0.5.4\n",
      "inflect                       6.0.4\n",
      "iniconfig                     2.0.0\n",
      "intel-openmp                  2023.1.0\n",
      "ipykernel                     5.5.6\n",
      "ipython                       7.34.0\n",
      "ipython-genutils              0.2.0\n",
      "ipython-sql                   0.4.1\n",
      "ipywidgets                    7.7.1\n",
      "itsdangerous                  2.1.2\n",
      "jax                           0.4.8\n",
      "jaxlib                        0.4.7+cuda11.cudnn86\n",
      "jieba                         0.42.1\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.2.0\n",
      "jsonpickle                    3.0.1\n",
      "jsonschema                    4.3.3\n",
      "jupyter-client                6.1.12\n",
      "jupyter-console               6.1.0\n",
      "jupyter_core                  5.3.0\n",
      "jupyter-server                1.24.0\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab-widgets            3.0.7\n",
      "kaggle                        1.5.13\n",
      "keras                         2.12.0\n",
      "kiwisolver                    1.4.4\n",
      "korean-lunar-calendar         0.3.1\n",
      "langcodes                     3.3.0\n",
      "latex2mathml                  3.75.3\n",
      "lazy_loader                   0.2\n",
      "libclang                      16.0.0\n",
      "librosa                       0.10.0.post2\n",
      "lightgbm                      3.3.5\n",
      "linkify-it-py                 2.0.2\n",
      "lit                           16.0.2\n",
      "llvmlite                      0.39.1\n",
      "locket                        1.0.0\n",
      "logical-unification           0.4.5\n",
      "LunarCalendar                 0.0.9\n",
      "lxml                          4.9.2\n",
      "Markdown                      3.4.3\n",
      "markdown-it-py                2.2.0\n",
      "MarkupSafe                    2.1.2\n",
      "matplotlib                    3.7.1\n",
      "matplotlib-inline             0.1.6\n",
      "matplotlib-venn               0.11.9\n",
      "mdit-py-plugins               0.3.3\n",
      "mdtex2html                    1.2.0\n",
      "mdurl                         0.1.2\n",
      "miniKanren                    1.0.3\n",
      "missingno                     0.5.2\n",
      "mistune                       0.8.4\n",
      "mizani                        0.8.1\n",
      "mkl                           2019.0\n",
      "ml-dtypes                     0.1.0\n",
      "mlxtend                       0.14.0\n",
      "more-itertools                9.1.0\n",
      "moviepy                       1.0.3\n",
      "mpmath                        1.3.0\n",
      "msgpack                       1.0.5\n",
      "multidict                     6.0.4\n",
      "multipledispatch              0.6.0\n",
      "multitasking                  0.0.11\n",
      "murmurhash                    1.0.9\n",
      "music21                       8.1.0\n",
      "natsort                       8.3.1\n",
      "nbclient                      0.7.4\n",
      "nbconvert                     6.5.4\n",
      "nbformat                      5.8.0\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      3.1\n",
      "nibabel                       3.0.2\n",
      "nltk                          3.8.1\n",
      "notebook                      6.4.8\n",
      "numba                         0.56.4\n",
      "numexpr                       2.8.4\n",
      "numpy                         1.22.4\n",
      "oauth2client                  4.1.3\n",
      "oauthlib                      3.2.2\n",
      "opencv-contrib-python         4.7.0.72\n",
      "opencv-python                 4.7.0.72\n",
      "opencv-python-headless        4.7.0.72\n",
      "openpyxl                      3.0.10\n",
      "opt-einsum                    3.3.0\n",
      "optax                         0.1.5\n",
      "orbax-checkpoint              0.2.1\n",
      "orjson                        3.8.11\n",
      "osqp                          0.6.2.post8\n",
      "packaging                     23.1\n",
      "palettable                    3.3.3\n",
      "pandas                        1.5.3\n",
      "pandas-datareader             0.10.0\n",
      "pandas-gbq                    0.17.9\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.14.4\n",
      "param                         1.13.0\n",
      "parso                         0.8.3\n",
      "partd                         1.4.0\n",
      "pathlib                       1.0.1\n",
      "pathy                         0.10.1\n",
      "patsy                         0.5.3\n",
      "pep517                        0.13.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        8.4.0\n",
      "pip                           23.0.1\n",
      "pip-tools                     6.6.2\n",
      "platformdirs                  3.3.0\n",
      "plotly                        5.13.1\n",
      "plotnine                      0.10.1\n",
      "pluggy                        1.0.0\n",
      "polars                        0.17.3\n",
      "pooch                         1.6.0\n",
      "portpicker                    1.3.9\n",
      "prefetch-generator            1.0.3\n",
      "preshed                       3.0.8\n",
      "prettytable                   0.7.2\n",
      "proglog                       0.1.10\n",
      "progressbar2                  4.2.0\n",
      "prometheus-client             0.16.0\n",
      "promise                       2.3\n",
      "prompt-toolkit                3.0.38\n",
      "prophet                       1.1.2\n",
      "proto-plus                    1.22.2\n",
      "protobuf                      3.20.3\n",
      "psutil                        5.9.5\n",
      "psycopg2                      2.9.6\n",
      "ptyprocess                    0.7.0\n",
      "py-cpuinfo                    9.0.0\n",
      "py4j                          0.10.9.7\n",
      "pyarrow                       9.0.0\n",
      "pyasn1                        0.5.0\n",
      "pyasn1-modules                0.3.0\n",
      "pycocotools                   2.0.6\n",
      "pycparser                     2.21\n",
      "pyct                          0.5.0\n",
      "pydantic                      1.10.7\n",
      "pydata-google-auth            1.7.0\n",
      "pydot                         1.4.2\n",
      "pydot-ng                      2.0.0\n",
      "pydotplus                     2.0.2\n",
      "PyDrive                       1.3.1\n",
      "pydub                         0.25.1\n",
      "pyerfa                        2.0.0.3\n",
      "pygame                        2.3.0\n",
      "Pygments                      2.14.0\n",
      "PyGObject                     3.36.0\n",
      "pymc                          5.1.2\n",
      "PyMeeus                       0.5.12\n",
      "pymystem3                     0.2.0\n",
      "PyOpenGL                      3.1.6\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.19.3\n",
      "PySocks                       1.7.1\n",
      "pytensor                      2.10.1\n",
      "pytest                        7.2.2\n",
      "python-apt                    0.0.0\n",
      "python-dateutil               2.8.2\n",
      "python-louvain                0.16\n",
      "python-multipart              0.0.6\n",
      "python-slugify                8.0.1\n",
      "python-utils                  3.5.2\n",
      "pytz                          2022.7.1\n",
      "pytz-deprecation-shim         0.1.0.post0\n",
      "pyviz-comms                   2.2.1\n",
      "PyWavelets                    1.4.1\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.1\n",
      "qdldl                         0.1.7\n",
      "qudida                        0.0.4\n",
      "regex                         2022.10.31\n",
      "requests                      2.27.1\n",
      "requests-oauthlib             1.3.1\n",
      "requests-unixsocket           0.2.0\n",
      "rich                          13.3.4\n",
      "rpy2                          3.5.5\n",
      "rsa                           4.9\n",
      "scikit-image                  0.19.3\n",
      "scikit-learn                  1.2.2\n",
      "scipy                         1.10.1\n",
      "scs                           3.2.3\n",
      "seaborn                       0.12.2\n",
      "semantic-version              2.10.0\n",
      "Send2Trash                    1.8.0\n",
      "sentencepiece                 0.1.99\n",
      "setuptools                    67.7.2\n",
      "shapely                       2.0.1\n",
      "six                           1.16.0\n",
      "sklearn-pandas                2.2.0\n",
      "smart-open                    6.3.0\n",
      "sniffio                       1.3.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "soundfile                     0.12.1\n",
      "soupsieve                     2.4.1\n",
      "soxr                          0.3.5\n",
      "spacy                         3.5.2\n",
      "spacy-legacy                  3.0.12\n",
      "spacy-loggers                 1.0.4\n",
      "Sphinx                        3.5.4\n",
      "sphinxcontrib-applehelp       1.0.4\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.1\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "SQLAlchemy                    2.0.10\n",
      "sqlparse                      0.4.4\n",
      "srsly                         2.4.6\n",
      "starlette                     0.26.1\n",
      "statsmodels                   0.13.5\n",
      "sympy                         1.11.1\n",
      "tables                        3.8.0\n",
      "tabulate                      0.8.10\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.2\n",
      "tensorboard                   2.12.2\n",
      "tensorboard-data-server       0.7.0\n",
      "tensorboard-plugin-wit        1.8.1\n",
      "tensorflow                    2.12.0\n",
      "tensorflow-datasets           4.8.3\n",
      "tensorflow-estimator          2.12.0\n",
      "tensorflow-gcs-config         2.12.0\n",
      "tensorflow-hub                0.13.0\n",
      "tensorflow-io-gcs-filesystem  0.32.0\n",
      "tensorflow-metadata           1.13.1\n",
      "tensorflow-probability        0.19.0\n",
      "tensorstore                   0.1.36\n",
      "termcolor                     2.3.0\n",
      "terminado                     0.17.1\n",
      "text-unidecode                1.3\n",
      "textblob                      0.17.1\n",
      "tf-slim                       1.1.0\n",
      "thinc                         8.1.9\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2023.4.12\n",
      "tinycss2                      1.2.1\n",
      "tokenizers                    0.13.3\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "toolz                         0.12.0\n",
      "torch                         2.0.0+cu118\n",
      "torchaudio                    2.0.1+cu118\n",
      "torchdata                     0.6.0\n",
      "torchsummary                  1.5.1\n",
      "torchtext                     0.15.1\n",
      "torchvision                   0.15.1+cu118\n",
      "tornado                       6.2\n",
      "tqdm                          4.65.0\n",
      "traitlets                     5.7.1\n",
      "transformers                  4.27.1\n",
      "triton                        2.0.0\n",
      "tweepy                        4.13.0\n",
      "typer                         0.7.0\n",
      "typing_extensions             4.5.0\n",
      "tzdata                        2023.3\n",
      "tzlocal                       4.3\n",
      "uc-micro-py                   1.0.2\n",
      "uritemplate                   4.1.1\n",
      "urllib3                       1.26.15\n",
      "uvicorn                       0.22.0\n",
      "vega-datasets                 0.9.0\n",
      "wasabi                        1.1.1\n",
      "wcwidth                       0.2.6\n",
      "webcolors                     1.13\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.5.1\n",
      "websockets                    11.0.2\n",
      "Werkzeug                      2.3.0\n",
      "wheel                         0.40.0\n",
      "widgetsnbextension            3.6.4\n",
      "wordcloud                     1.8.2.2\n",
      "wrapt                         1.14.1\n",
      "xarray                        2022.12.0\n",
      "xarray-einstats               0.5.1\n",
      "xgboost                       1.7.5\n",
      "xlrd                          2.0.1\n",
      "yarl                          1.9.2\n",
      "yellowbrick                   1.5\n",
      "yfinance                      0.2.18\n",
      "zict                          3.0.0\n",
      "zipp                          3.15.0\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# Colab执行以下命令前需import以上的库，否则出错\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7689,
     "status": "ok",
     "timestamp": 1683187669620,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "MFubab9TfO_s",
    "outputId": "175c5a48-d2ee-46d6-e376-6badac027f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_chinese\n",
      "  Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.1/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     --- ------------------------------------ 0.1/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 0.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 0.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.5/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.6/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.8/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 0.9/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.0/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.2/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.3/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.5/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.6 MB/s eta 0:00:00\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.2/19.2 MB 4.6 MB/s eta 0:00:05\n",
      "      --------------------------------------- 0.3/19.2 MB 5.0 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.5/19.2 MB 5.0 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.7/19.2 MB 4.9 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.9/19.2 MB 5.1 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 1.1/19.2 MB 5.1 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 1.3/19.2 MB 5.4 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.5/19.2 MB 5.2 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.7/19.2 MB 5.4 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.9/19.2 MB 5.6 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 2.2/19.2 MB 5.7 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 2.4/19.2 MB 5.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 2.7/19.2 MB 5.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.9/19.2 MB 6.0 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 3.2/19.2 MB 6.0 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 3.4/19.2 MB 6.1 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 3.7/19.2 MB 6.2 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 4.0/19.2 MB 6.2 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 4.3/19.2 MB 6.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 4.6/19.2 MB 6.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 4.9/19.2 MB 6.5 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 5.2/19.2 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 5.5/19.2 MB 6.8 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 5.9/19.2 MB 6.8 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 6.2/19.2 MB 6.9 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 6.5/19.2 MB 7.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 6.9/19.2 MB 7.2 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 7.2/19.2 MB 7.2 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 7.6/19.2 MB 7.4 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 8.0/19.2 MB 7.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 8.4/19.2 MB 7.5 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 8.8/19.2 MB 7.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 9.2/19.2 MB 7.8 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 9.6/19.2 MB 7.8 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 10.0/19.2 MB 8.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 10.4/19.2 MB 8.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 10.8/19.2 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 11.3/19.2 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 11.7/19.2 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 12.2/19.2 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 12.6/19.2 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 13.1/19.2 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 13.5/19.2 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 14.0/19.2 MB 10.6 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 14.5/19.2 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 15.0/19.2 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 15.5/19.2 MB 11.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 16.1/19.2 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 16.6/19.2 MB 12.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 17.1/19.2 MB 12.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 17.6/19.2 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 18.2/19.2 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 18.7/19.2 MB 12.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  19.2/19.2 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  19.2/19.2 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 19.2/19.2 MB 12.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "     ---------------------------------------- 0.0/474.6 kB ? eta -:--:--\n",
      "     ---------------------------- -------- 368.6/474.6 kB 11.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 474.6/474.6 kB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from rouge_chinese) (1.16.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 0.0/298.0 kB ? eta -:--:--\n",
      "     ------------------------------------- 298.0/298.0 kB 18.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: packaging in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (2023.4.0)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.0-cp310-cp310-win_amd64.whl (21.5 MB)\n",
      "     ---------------------------------------- 0.0/21.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.6/21.5 MB 17.8 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.1/21.5 MB 17.2 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.6/21.5 MB 17.4 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 2.2/21.5 MB 17.4 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 2.8/21.5 MB 16.3 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 3.4/21.5 MB 16.7 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 4.1/21.5 MB 17.4 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 4.7/21.5 MB 16.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 5.3/21.5 MB 16.9 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 5.9/21.5 MB 17.2 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 6.6/21.5 MB 16.9 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 7.2/21.5 MB 17.2 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 7.9/21.5 MB 17.4 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 8.6/21.5 MB 17.1 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 9.3/21.5 MB 17.4 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 10.0/21.5 MB 17.8 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 10.6/21.5 MB 17.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 11.3/21.5 MB 17.7 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 12.1/21.5 MB 18.2 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 12.8/21.5 MB 18.2 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 13.6/21.5 MB 18.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 14.3/21.5 MB 18.7 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 15.0/21.5 MB 18.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 15.8/21.5 MB 19.3 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 16.6/21.5 MB 19.9 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 17.3/21.5 MB 19.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 18.1/21.5 MB 19.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 18.9/21.5 MB 20.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 19.6/21.5 MB 20.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 20.4/21.5 MB 20.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  21.2/21.5 MB 21.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  21.5/21.5 MB 20.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  21.5/21.5 MB 20.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 21.5/21.5 MB 18.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (0.14.1)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ---------------------------------------- 0.0/110.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 110.5/110.5 kB 6.7 MB/s eta 0:00:00\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "     ---------------------------------------- 0.0/134.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 134.3/134.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\programdata\\anaconda3\\envs\\hoho_chatgpt\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314474 sha256=f9ea3faa6bbac95a9ec9835b016e0e57586488698a5ce05ebf2ff3cfbf5b1590\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\c9\\69\\31\\d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba, xxhash, rouge_chinese, pyarrow, joblib, dill, responses, nltk, multiprocess, datasets\n",
      "Successfully installed datasets-2.12.0 dill-0.3.6 jieba-0.42.1 joblib-1.2.0 multiprocess-0.70.14 nltk-3.8.1 pyarrow-12.0.0 responses-0.18.0 rouge_chinese-1.0.3 xxhash-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_chinese nltk jieba datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683186128714,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "4JEfLBRPgqAw",
    "outputId": "f27a2eef-1b42-4bb4-f8c4-a22fe77bf433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1683186454462,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "8lSIFryLthAW",
    "outputId": "df5a0f1b-0666-4175-b2db-d5b8ca8c2142"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev.json', 'train.json']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f'{root_dir}/MyDrive/ChatGLM-6B-main/ptuning/AdvertiseGen/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1683186521889,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "KiyiWVSVuXWK",
    "outputId": "ddb64d68-144e-4fbb-8016-566aa084f889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683186560080,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "ha63Tv2pu14Q"
   },
   "outputs": [],
   "source": [
    "!cd gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1683187643263,
     "user": {
      "displayName": "Valentine Kevin",
      "userId": "09325380893251256195"
     },
     "user_tz": -480
    },
    "id": "yRgJtDgEvKX7",
    "outputId": "61452174-7d72-44e8-875a-349c2112ea20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foIjCRuEvLec",
    "outputId": "85756636-ea1c-4618-a9c0-11b4ae9e382b"
   },
   "outputs": [],
   "source": [
    "# !bash /content/gdrive/MyDrive/ChatGLM-6B-main/ptuning/train-colab.sh\n",
    "!bash ./ChatGLM-6B-main/ptuning/train_hoho.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_ZeeJyyxfmY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50HrMPnBACFY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOmIIk7w40K2YdvbFBUYJZL",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
